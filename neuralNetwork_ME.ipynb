{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "711ba8d491044b5c",
   "metadata": {},
   "source": [
    "# Neural Network for blood cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dede463cd1b30da2",
   "metadata": {},
   "source": [
    "**Der Datensatz besteht aus mikroskopischen Bildern von Blutzellen, diese sind in acht Kategorien aufgeteilt:**\n",
    "1. basophil\n",
    "2. eosinophil\n",
    "3. erythroblast\n",
    "4. ig\n",
    "5. lymphocyte\n",
    "6. monocyte\n",
    "7. neutrophil\n",
    "8. platelet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cbdd91c2b5da01",
   "metadata": {},
   "source": [
    "## Daten importieren und vorbereiten\n",
    "Die Daten werden aus dem Verzeichnis geladen und verarbeitet. Die grösse wird auf 224 x 224 Pixel gesetzt und die Bilder werden durchgemischt und in Batches mit je 32 Bildern geladen. 20% der Daten werden zur validation behalten. Die verbleibenden 80% werden erneut aufgeteilt, wobei 80% als Trainingsdaten und 20% als Validierungsdaten dienen. Dies führt zu einem Trainingssatz mit 64%, einem Validierungssatz mit 16% und einem Testdatensatz mit 20% der Bilder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ce5c3edc4b50d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# forcing a reset in the jupyter notebook\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17092 files belonging to 8 classes.\n",
      "Using 13674 files for training.\n",
      "Using 3418 files for validation.\n",
      "['basophil', 'eosinophil', 'erythroblast', 'ig', 'lymphocyte', 'monocyte', 'neutrophil', 'platelet']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# Import and prepare the first split of datasets\n",
    "path = os.path.join(\"images/archive/bloodcells_dataset/\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "# Use image_dataset_from_directory to load your data\n",
    "dataset, test_dataset = keras.utils.image_dataset_from_directory(\n",
    "    directory=path,\n",
    "    image_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode=\"int\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Get class names\n",
    "class_names = dataset.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e242546d363b4418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plot 16 images from the dataset as examples\n",
    "fig, ax = plt.subplots(3, 3, figsize=(10,10))\n",
    "ax = ax.flat\n",
    "for images, labels in dataset.take(1):\n",
    "  for i in range(9):\n",
    "    ax[i].set_title(class_names[labels[i].numpy()])\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "    ax[i].imshow(images[i].numpy().astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30e2206f8bfbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert labels to NumPy array\n",
    "labels_array = np.concatenate([labels.numpy() for images, labels in dataset], axis=0)\n",
    "\n",
    "# Get the class distribution from the dataset\n",
    "class_distribution = [np.sum(labels_array == i) for i in range(len(class_names))]\n",
    "\n",
    "# Calculate the percentage distribution\n",
    "total_samples = sum(class_distribution)\n",
    "class_percentages = [(count / total_samples) * 100 for count in class_distribution]\n",
    "\n",
    "# Create a countplot using seaborn with percentages\n",
    "sns.barplot(x=class_names, y=class_percentages)\n",
    "plt.xlabel('Blood Cell Categories')\n",
    "plt.ylabel('Percentage of Images')\n",
    "plt.title('Percentage Distribution of Blood Cell Categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a23a5e921ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the total number of elements in the dataset\n",
    "num_elements = len(dataset)\n",
    "\n",
    "# Calculate the size of the training set (80% of the total dataset)\n",
    "train_size = int(0.8 * num_elements)\n",
    "\n",
    "# Skip the first 'train_size' elements to create the validation dataset\n",
    "# and prefetch the data for improved performance\n",
    "val_dataset = dataset.skip(train_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Take the first 'train_size' elements to create the training dataset\n",
    "# and prefetch the data for improved performance\n",
    "train_dataset = dataset.take(train_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Check the lengths of the resulting datasets\n",
    "len(train_dataset), len(val_dataset), len(test_dataset) # Output is in batches, BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed14a883e7b8c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check format of the batches, should be -> (32, 224, 224, 3)\n",
    "for image_batch, labels_batch in train_dataset.take(1):\n",
    "  print(f\"Train data: {image_batch.shape}\")\n",
    "  print(f\"Train labels: {labels_batch.shape}\")\n",
    "\n",
    "for image_batch, labels_batch in val_dataset.take(1):\n",
    "  print(f\"Validation data: {image_batch.shape}\")\n",
    "  print(f\"Validation labels: {labels_batch.shape}\")\n",
    "\n",
    "for image_batch, labels_batch in test_dataset.take(1):\n",
    "  print(f\"Test data: {image_batch.shape}\")\n",
    "  print(f\"Test labels: {labels_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600cc0c7fbfd051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check pixel intesities\n",
    "for image, label in train_dataset.take(1):\n",
    "  print(tf.reduce_max(image))\n",
    "  print(tf.reduce_min(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f511b59ebcdd9",
   "metadata": {},
   "source": [
    "**Fazit:**\n",
    "* Die 8 Klassen sind unausgeglichen, wobei die häufigste Klasse die Neutrophilen mit 19,4% aller Bilder und die seltenste Klasse die Lymphozyten mit 7,1% ist. Daher würde die Genauigkeit eines zufälligen Modells 19,4% betragen.\n",
    "* Die Pixelintensitäten reichen von 3,5 bis 255. Daher ist eine Neuskalierung der Pixelintensitäten angemessen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2044909cf9ac497",
   "metadata": {},
   "source": [
    "## Model 1 - Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a773090014dd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Implement a call back function. Stopps after quantity stopps improving\n",
    "callBack = EarlyStopping(monitor='val_loss', patience=3, restore_best_weight=True)\n",
    "\n",
    "# Set the seed for TensorFlow operations\n",
    "tf.random.set_seed(24)\n",
    "# Defining a simple CNN model\n",
    "model1 = keras.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activision='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH,3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activision='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(), \n",
    "    layers.Dense(128, activision='relu'),\n",
    "    layers.Dense(8, activision='softmax')\n",
    "])\n",
    "\n",
    "model1.summary()\n",
    "\n",
    "# Compiling the model\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "history1 = model1.fit(train_dataset, validation_data=val_dataset, epochs=10, callbacks=[callBack])\n",
    "\n",
    "result1 = model1.evaluate(test_dataset)\n",
    "\n",
    "print(\"Test Loss:\", result1[0])\n",
    "print(\"Test Accuracy:\", result1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f614a4529375498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b662db00be13b4d",
   "metadata": {},
   "source": [
    "## Model 2 - InceptionV3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8a7fec76d23469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  keras.applications import InceptionV3\n",
    "\n",
    "base_model2 = InceptionV3(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), \n",
    "                     include_top=False,\n",
    "                     weights='imagenet')\n",
    "\n",
    "base_model2.trainable = False\n",
    "\n",
    "model2 = keras.Sequential([\n",
    "    base_model2,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "history2 = model2.evaluate(train_dataset, validattion_data=val_dataset, epochs=10)\n",
    "\n",
    "result2 = model2.evaluate(test_dataset)\n",
    "print('Test Loss: ', result2[0])\n",
    "print('Test Accuracy: ', result2[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
